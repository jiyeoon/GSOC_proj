{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bcc63a-592f-48f0-a0eb-f60188678d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb3391-7144-44a7-954d-8485e8e27c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb12175-f58b-4c6d-80fb-bdeea41115c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = './conv_2d.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d636b07e-0443-4985-9382-52ff26d88b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.lite.python.interpreter.Interpreter at 0x7f93945eaf28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=SAVED_MODEL_PATH)\n",
    "interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cafab303-de00-40dd-81be-db7abfbdd896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Interpreter in module tensorflow.lite.python.interpreter object:\n",
      "\n",
      "class Interpreter(builtins.object)\n",
      " |  Interpreter interface for TensorFlow Lite Models.\n",
      " |  \n",
      " |  This makes the TensorFlow Lite interpreter accessible in Python.\n",
      " |  It is possible to use this interpreter in a multithreaded Python environment,\n",
      " |  but you must be sure to call functions of a particular instance from only\n",
      " |  one thread at a time. So if you want to have 4 threads running different\n",
      " |  inferences simultaneously, create  an interpreter for each one as thread-local\n",
      " |  data. Similarly, if you are calling invoke() in one thread on a single\n",
      " |  interpreter but you want to use tensor() on another thread once it is done,\n",
      " |  you must use a synchronization primitive between the threads to ensure invoke\n",
      " |  has returned before calling tensor().\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __init__(self, model_path=None, model_content=None, experimental_delegates=None, num_threads=None, experimental_op_resolver_type=<OpResolverType.AUTO: 0>, experimental_preserve_all_tensors=False)\n",
      " |      Constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_path: Path to TF-Lite Flatbuffer file.\n",
      " |        model_content: Content of model.\n",
      " |        experimental_delegates: Experimental. Subject to change. List of\n",
      " |          [TfLiteDelegate](https://www.tensorflow.org/lite/performance/delegates)\n",
      " |            objects returned by lite.load_delegate().\n",
      " |        num_threads: Sets the number of threads used by the interpreter and\n",
      " |          available to CPU kernels. If not set, the interpreter will use an\n",
      " |          implementation-dependent default number of threads. Currently, only a\n",
      " |          subset of kernels, such as conv, support multi-threading.\n",
      " |        experimental_op_resolver_type: The op resolver used by the interpreter. It\n",
      " |          must be an instance of OpResolverType. By default, we use the built-in\n",
      " |          op resolver which corresponds to tflite::ops::builtin::BuiltinOpResolver\n",
      " |          in C++.\n",
      " |        experimental_preserve_all_tensors: If true, then intermediate tensors\n",
      " |          used during computation are preserved for inspection. Otherwise, reading\n",
      " |          intermediate tensors provides undefined values.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the interpreter was unable to create.\n",
      " |  \n",
      " |  allocate_tensors(self)\n",
      " |  \n",
      " |  get_input_details(self)\n",
      " |      Gets model input details.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of input details.\n",
      " |  \n",
      " |  get_output_details(self)\n",
      " |      Gets model output details.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of output details.\n",
      " |  \n",
      " |  get_signature_list(self)\n",
      " |      Gets list of SignatureDefs in the model.\n",
      " |      \n",
      " |      Example,\n",
      " |      ```\n",
      " |      signatures = interpreter.get_signature_list()\n",
      " |      print(signatures)\n",
      " |      \n",
      " |      # {\n",
      " |      #   'add': {'inputs': ['x', 'y'], 'outputs': ['output_0']}\n",
      " |      # }\n",
      " |      \n",
      " |      Then using the names in the signature list you can get a callable from\n",
      " |      get_signature_runner().\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of SignatureDef details in a dictionary structure.\n",
      " |        It is keyed on the SignatureDef method name, and the value holds\n",
      " |        dictionary of inputs and outputs.\n",
      " |  \n",
      " |  get_signature_runner(self, method_name=None)\n",
      " |      Gets callable for inference of specific SignatureDef.\n",
      " |      \n",
      " |      Example usage,\n",
      " |      ```\n",
      " |      interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
      " |      interpreter.allocate_tensors()\n",
      " |      fn = interpreter.get_signature_runner('div_with_remainder')\n",
      " |      output = fn(x=np.array([3]), y=np.array([2]))\n",
      " |      print(output)\n",
      " |      # {\n",
      " |      #   'quotient': array([1.], dtype=float32)\n",
      " |      #   'remainder': array([1.], dtype=float32)\n",
      " |      # }\n",
      " |      ```\n",
      " |      \n",
      " |      None can be passed for method_name if the model has a single Signature only.\n",
      " |      \n",
      " |      All names used are this specific SignatureDef names.\n",
      " |      \n",
      " |      \n",
      " |      Args:\n",
      " |        method_name: The exported method name for the SignatureDef, it can be None\n",
      " |          if and only if the model has a single SignatureDef. Default value is\n",
      " |          None.\n",
      " |      \n",
      " |      Returns:\n",
      " |        This returns a callable that can run inference for SignatureDef defined\n",
      " |        by argument 'method_name'.\n",
      " |        The callable will take key arguments corresponding to the arguments of the\n",
      " |        SignatureDef, that should have numpy values.\n",
      " |        The callable will returns dictionary that maps from output names to numpy\n",
      " |        values of the computed results.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If passed method_name is invalid.\n",
      " |  \n",
      " |  get_tensor(self, tensor_index)\n",
      " |      Gets the value of the output tensor (get a copy).\n",
      " |      \n",
      " |      If you wish to avoid the copy, use `tensor()`. This function cannot be used\n",
      " |      to read intermediate results.\n",
      " |      \n",
      " |      Args:\n",
      " |        tensor_index: Tensor index of tensor to get. This value can be gotten from\n",
      " |          the 'index' field in get_output_details.\n",
      " |      \n",
      " |      Returns:\n",
      " |        a numpy array.\n",
      " |  \n",
      " |  get_tensor_details(self)\n",
      " |      Gets tensor details for every tensor with valid tensor details.\n",
      " |      \n",
      " |      Tensors where required information about the tensor is not found are not\n",
      " |      added to the list. This includes temporary tensors without a name.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of dictionaries containing tensor information.\n",
      " |  \n",
      " |  invoke(self)\n",
      " |      Invoke the interpreter.\n",
      " |      \n",
      " |      Be sure to set the input sizes, allocate tensors and fill values before\n",
      " |      calling this. Also, note that this function releases the GIL so heavy\n",
      " |      computation can be done in the background while the Python interpreter\n",
      " |      continues. No other function on this object should be called while the\n",
      " |      invoke() call has not finished.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When the underlying interpreter fails raise ValueError.\n",
      " |  \n",
      " |  reset_all_variables(self)\n",
      " |  \n",
      " |  resize_tensor_input(self, input_index, tensor_size, strict=False)\n",
      " |      Resizes an input tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_index: Tensor index of input to set. This value can be gotten from\n",
      " |          the 'index' field in get_input_details.\n",
      " |        tensor_size: The tensor_shape to resize the input to.\n",
      " |        strict: Only unknown dimensions can be resized when `strict` is True.\n",
      " |          Unknown dimensions are indicated as `-1` in the `shape_signature`\n",
      " |          attribute of a given tensor. (default False)\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the interpreter could not resize the input tensor.\n",
      " |      \n",
      " |      Usage:\n",
      " |      ```\n",
      " |      interpreter = Interpreter(model_content=tflite_model)\n",
      " |      interpreter.resize_tensor_input(0, [num_test_images, 224, 224, 3])\n",
      " |      interpreter.allocate_tensors()\n",
      " |      interpreter.set_tensor(0, test_images)\n",
      " |      interpreter.invoke()\n",
      " |      ```\n",
      " |  \n",
      " |  set_tensor(self, tensor_index, value)\n",
      " |      Sets the value of the input tensor.\n",
      " |      \n",
      " |      Note this copies data in `value`.\n",
      " |      \n",
      " |      If you want to avoid copying, you can use the `tensor()` function to get a\n",
      " |      numpy buffer pointing to the input buffer in the tflite interpreter.\n",
      " |      \n",
      " |      Args:\n",
      " |        tensor_index: Tensor index of tensor to set. This value can be gotten from\n",
      " |          the 'index' field in get_input_details.\n",
      " |        value: Value of tensor to set.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the interpreter could not set the tensor.\n",
      " |  \n",
      " |  tensor(self, tensor_index)\n",
      " |      Returns function that gives a numpy view of the current tensor buffer.\n",
      " |      \n",
      " |      This allows reading and writing to this tensors w/o copies. This more\n",
      " |      closely mirrors the C++ Interpreter class interface's tensor() member, hence\n",
      " |      the name. Be careful to not hold these output references through calls\n",
      " |      to `allocate_tensors()` and `invoke()`. This function cannot be used to read\n",
      " |      intermediate results.\n",
      " |      \n",
      " |      Usage:\n",
      " |      \n",
      " |      ```\n",
      " |      interpreter.allocate_tensors()\n",
      " |      input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
      " |      output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
      " |      for i in range(10):\n",
      " |        input().fill(3.)\n",
      " |        interpreter.invoke()\n",
      " |        print(\"inference %s\" % output())\n",
      " |      ```\n",
      " |      \n",
      " |      Notice how this function avoids making a numpy array directly. This is\n",
      " |      because it is important to not hold actual numpy views to the data longer\n",
      " |      than necessary. If you do, then the interpreter can no longer be invoked,\n",
      " |      because it is possible the interpreter would resize and invalidate the\n",
      " |      referenced tensors. The NumPy API doesn't allow any mutability of the\n",
      " |      the underlying buffers.\n",
      " |      \n",
      " |      WRONG:\n",
      " |      \n",
      " |      ```\n",
      " |      input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])()\n",
      " |      output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])()\n",
      " |      interpreter.allocate_tensors()  # This will throw RuntimeError\n",
      " |      for i in range(10):\n",
      " |        input.fill(3.)\n",
      " |        interpreter.invoke()  # this will throw RuntimeError since input,output\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        tensor_index: Tensor index of tensor to get. This value can be gotten from\n",
      " |          the 'index' field in get_output_details.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function that can return a new numpy array pointing to the internal\n",
      " |        TFLite tensor state at any point. It is safe to hold the function forever,\n",
      " |        but it is not safe to hold the numpy array forever.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8525c177-675f-49eb-b9b1-88b80b905cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on InterpreterWrapper in module tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper object:\n",
      "\n",
      "class InterpreterWrapper(pybind11_builtins.pybind11_object)\n",
      " |  Method resolution order:\n",
      " |      InterpreterWrapper\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  AllocateTensors(...)\n",
      " |      AllocateTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  GetOutputTensorFromSignatureDefName(...)\n",
      " |      GetOutputTensorFromSignatureDefName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: str, arg1: str) -> object\n",
      " |  \n",
      " |  GetSignatureDefs(...)\n",
      " |      GetSignatureDefs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  GetTensor(...)\n",
      " |      GetTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  InputIndices(...)\n",
      " |      InputIndices(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  Invoke(...)\n",
      " |      Invoke(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ModifyGraphWithDelegate(...)\n",
      " |      ModifyGraphWithDelegate(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Adds a delegate to the interpreter.\n",
      " |  \n",
      " |  NodeInputs(...)\n",
      " |      NodeInputs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  NodeName(...)\n",
      " |      NodeName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> str\n",
      " |  \n",
      " |  NodeOutputs(...)\n",
      " |      NodeOutputs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  NumNodes(...)\n",
      " |      NumNodes(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  NumTensors(...)\n",
      " |      NumTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  OutputIndices(...)\n",
      " |      OutputIndices(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ResetVariableTensors(...)\n",
      " |      ResetVariableTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ResizeInputTensor(...)\n",
      " |      ResizeInputTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int, arg1: handle, arg2: bool) -> object\n",
      " |  \n",
      " |  SetInputTensorFromSignatureDefName(...)\n",
      " |      SetInputTensorFromSignatureDefName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: str, arg1: str, arg2: handle) -> object\n",
      " |  \n",
      " |  SetNumThreads(...)\n",
      " |      SetNumThreads(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      ask the interpreter to set the number of threads to use.\n",
      " |  \n",
      " |  SetTensor(...)\n",
      " |      SetTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int, arg1: handle) -> object\n",
      " |  \n",
      " |  TensorName(...)\n",
      " |      TensorName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> str\n",
      " |  \n",
      " |  TensorQuantization(...)\n",
      " |      TensorQuantization(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Deprecated in favor of TensorQuantizationParameters.\n",
      " |  \n",
      " |  TensorQuantizationParameters(...)\n",
      " |      TensorQuantizationParameters(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSize(...)\n",
      " |      TensorSize(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSizeSignature(...)\n",
      " |      TensorSizeSignature(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSparsityParameters(...)\n",
      " |      TensorSparsityParameters(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorType(...)\n",
      " |      TensorType(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  interpreter(...)\n",
      " |      interpreter(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  tensor(...)\n",
      " |      tensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: handle, arg1: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Returns a reference to tensor index i as a numpy array. The\n",
      " |      base_object should be the interpreter object providing the memory.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(interpreter._interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de784d24-9f5e-4658-aff1-1e392bf6ce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'MobilenetV1/Conv2d_0/weights',\n",
       "  'index': 0,\n",
       "  'shape': array([32,  3,  3,  3], dtype=int32),\n",
       "  'shape_signature': array([32,  3,  3,  3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'MobilenetV1/MobilenetV1/Conv2d_0/Relu6',\n",
       "  'index': 1,\n",
       "  'shape': array([  1, 112, 112,  32], dtype=int32),\n",
       "  'shape_signature': array([  1, 112, 112,  32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'MobilenetV1/MobilenetV1/Conv2d_0/convolution_bias',\n",
       "  'index': 2,\n",
       "  'shape': array([32], dtype=int32),\n",
       "  'shape_signature': array([32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'input',\n",
       "  'index': 3,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'shape_signature': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8532c713-9e6a-4d71-8327-c913b7f7d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'op_name': 'CONV_2D',\n",
       "  'inputs': array([3, 0, 2], dtype=int32),\n",
       "  'outputs': array([1], dtype=int32)}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter._get_ops_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936bc39-b837-4b74-9d5d-0ddfe18c8b53",
   "metadata": {},
   "source": [
    "```c\n",
    "  const tflite::Interpreter* interpreter = ...; // Initialize interpreter\n",
    "  for (int op_index : interpreter->execution_plan()) {\n",
    "    const auto* op_and_reg = interpreter->node_and_registration(op_index);\n",
    "    if (op_and_reg->second.builtin_code == kTfLiteBuiltinConv2d) {\n",
    "      // Parse operation basing on its type.\n",
    "      // See other types in tensorflow/lite/builtin_ops.h\n",
    "    }\n",
    "    for (const auto input_idx :\n",
    "         tflite::TfLiteIntArrayView(op_and_reg->first.inputs)) {\n",
    "      // Access operation input using its index.\n",
    "    }\n",
    "    for (const auto output_idx :\n",
    "         tflite::TfLiteIntArrayView(op_and_reg->first.outputs)) {\n",
    "      // Access operation output using its index.\n",
    "    }\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e4bb4d-0f64-4e95-a3d7-e88f04a1cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter._interpreter.NumNodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d87ebfe-4c18-4aea-98a8-ddeeff516640",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter2 = tf.lite.Interpreter(model_path='./MODELS/densenet.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97493e12-1187-4a27-ac08-0d3c574c1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'op_name': 'CONV_2D', 'inputs': array([  0, 491, 490], dtype=int32), 'outputs': array([1], dtype=int32)}\n",
      "{'index': 1, 'op_name': 'MAX_POOL_2D', 'inputs': array([1], dtype=int32), 'outputs': array([497], dtype=int32)}\n",
      "{'index': 2, 'op_name': 'MUL', 'inputs': array([497,  13], dtype=int32), 'outputs': array([12], dtype=int32)}\n",
      "{'index': 3, 'op_name': 'ADD', 'inputs': array([12, 11], dtype=int32), 'outputs': array([10], dtype=int32)}\n",
      "{'index': 4, 'op_name': 'CONV_2D', 'inputs': array([10, 17, 16], dtype=int32), 'outputs': array([15], dtype=int32)}\n",
      "{'index': 5, 'op_name': 'CONCATENATION', 'inputs': array([497,  15], dtype=int32), 'outputs': array([14], dtype=int32)}\n",
      "{'index': 6, 'op_name': 'MUL', 'inputs': array([14, 21], dtype=int32), 'outputs': array([20], dtype=int32)}\n",
      "{'index': 7, 'op_name': 'ADD', 'inputs': array([20, 19], dtype=int32), 'outputs': array([18], dtype=int32)}\n",
      "{'index': 8, 'op_name': 'CONV_2D', 'inputs': array([18, 25, 24], dtype=int32), 'outputs': array([23], dtype=int32)}\n",
      "{'index': 9, 'op_name': 'CONCATENATION', 'inputs': array([14, 23], dtype=int32), 'outputs': array([22], dtype=int32)}\n",
      "{'index': 10, 'op_name': 'MUL', 'inputs': array([22, 29], dtype=int32), 'outputs': array([28], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# todo : 이게 왜 inputs와 outputs가 다른건지 한번 물어보자. 이런 쉐입은 그동안 없었는데 말이다..\n",
    "for op_index in range(interpreter2._interpreter.NumNodes()):\n",
    "    op_and_reg = interpreter2._get_op_details(op_index)\n",
    "    print(op_and_reg)\n",
    "    if op_index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e0f23b-b44d-46c8-9e95-efe0ab4813f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'op_name': 'CONV_2D',\n",
       "  'inputs': array([  0, 491, 490], dtype=int32),\n",
       "  'outputs': array([1], dtype=int32)},\n",
       " {'index': 1,\n",
       "  'op_name': 'MAX_POOL_2D',\n",
       "  'inputs': array([1], dtype=int32),\n",
       "  'outputs': array([497], dtype=int32)},\n",
       " {'index': 2,\n",
       "  'op_name': 'MUL',\n",
       "  'inputs': array([497,  13], dtype=int32),\n",
       "  'outputs': array([12], dtype=int32)},\n",
       " {'index': 3,\n",
       "  'op_name': 'ADD',\n",
       "  'inputs': array([12, 11], dtype=int32),\n",
       "  'outputs': array([10], dtype=int32)},\n",
       " {'index': 4,\n",
       "  'op_name': 'CONV_2D',\n",
       "  'inputs': array([10, 17, 16], dtype=int32),\n",
       "  'outputs': array([15], dtype=int32)},\n",
       " {'index': 5,\n",
       "  'op_name': 'CONCATENATION',\n",
       "  'inputs': array([497,  15], dtype=int32),\n",
       "  'outputs': array([14], dtype=int32)},\n",
       " {'index': 6,\n",
       "  'op_name': 'MUL',\n",
       "  'inputs': array([14, 21], dtype=int32),\n",
       "  'outputs': array([20], dtype=int32)},\n",
       " {'index': 7,\n",
       "  'op_name': 'ADD',\n",
       "  'inputs': array([20, 19], dtype=int32),\n",
       "  'outputs': array([18], dtype=int32)},\n",
       " {'index': 8,\n",
       "  'op_name': 'CONV_2D',\n",
       "  'inputs': array([18, 25, 24], dtype=int32),\n",
       "  'outputs': array([23], dtype=int32)},\n",
       " {'index': 9,\n",
       "  'op_name': 'CONCATENATION',\n",
       "  'inputs': array([14, 23], dtype=int32),\n",
       "  'outputs': array([22], dtype=int32)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter2._get_ops_details()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26dde181-0d73-4f63-bb76-dba798c8a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "print(len(interpreter2._get_ops_details()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cacac18-c668-4385-9386-777396c4f8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'block-0/batch_normalization/FusedBatchNorm_mul_0',\n",
       " 'index': 5,\n",
       " 'shape': array([  1,  56,  56, 256], dtype=int32),\n",
       " 'shape_signature': array([  1,  56,  56, 256], dtype=int32),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter2.get_tensor_details()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fd5f74-8fab-47bf-8e98-2dee0f0e936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on InterpreterWrapper in module tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper object:\n",
      "\n",
      "class InterpreterWrapper(pybind11_builtins.pybind11_object)\n",
      " |  Method resolution order:\n",
      " |      InterpreterWrapper\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  AllocateTensors(...)\n",
      " |      AllocateTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  GetOutputTensorFromSignatureDefName(...)\n",
      " |      GetOutputTensorFromSignatureDefName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: str, arg1: str) -> object\n",
      " |  \n",
      " |  GetSignatureDefs(...)\n",
      " |      GetSignatureDefs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  GetTensor(...)\n",
      " |      GetTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  InputIndices(...)\n",
      " |      InputIndices(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  Invoke(...)\n",
      " |      Invoke(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ModifyGraphWithDelegate(...)\n",
      " |      ModifyGraphWithDelegate(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Adds a delegate to the interpreter.\n",
      " |  \n",
      " |  NodeInputs(...)\n",
      " |      NodeInputs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  NodeName(...)\n",
      " |      NodeName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> str\n",
      " |  \n",
      " |  NodeOutputs(...)\n",
      " |      NodeOutputs(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  NumNodes(...)\n",
      " |      NumNodes(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  NumTensors(...)\n",
      " |      NumTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  OutputIndices(...)\n",
      " |      OutputIndices(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ResetVariableTensors(...)\n",
      " |      ResetVariableTensors(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> object\n",
      " |  \n",
      " |  ResizeInputTensor(...)\n",
      " |      ResizeInputTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int, arg1: handle, arg2: bool) -> object\n",
      " |  \n",
      " |  SetInputTensorFromSignatureDefName(...)\n",
      " |      SetInputTensorFromSignatureDefName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: str, arg1: str, arg2: handle) -> object\n",
      " |  \n",
      " |  SetNumThreads(...)\n",
      " |      SetNumThreads(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      ask the interpreter to set the number of threads to use.\n",
      " |  \n",
      " |  SetTensor(...)\n",
      " |      SetTensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int, arg1: handle) -> object\n",
      " |  \n",
      " |  TensorName(...)\n",
      " |      TensorName(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> str\n",
      " |  \n",
      " |  TensorQuantization(...)\n",
      " |      TensorQuantization(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Deprecated in favor of TensorQuantizationParameters.\n",
      " |  \n",
      " |  TensorQuantizationParameters(...)\n",
      " |      TensorQuantizationParameters(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSize(...)\n",
      " |      TensorSize(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSizeSignature(...)\n",
      " |      TensorSizeSignature(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorSparsityParameters(...)\n",
      " |      TensorSparsityParameters(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  TensorType(...)\n",
      " |      TensorType(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: int) -> object\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  interpreter(...)\n",
      " |      interpreter(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper) -> int\n",
      " |  \n",
      " |  tensor(...)\n",
      " |      tensor(self: tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper, arg0: handle, arg1: int) -> object\n",
      " |      \n",
      " |      \n",
      " |      Returns a reference to tensor index i as a numpy array. The\n",
      " |      base_object should be the interpreter object providing the memory.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(interpreter2._interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c80214a-5d73-4d08-aa8f-51db9dcb3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname('__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0bea84f-b759-439e-853b-82623ad67c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'op_name': 'CONV_2D',\n",
       "  'inputs': array([  0, 491, 490], dtype=int32),\n",
       "  'outputs': array([1], dtype=int32)},\n",
       " {'index': 1,\n",
       "  'op_name': 'MAX_POOL_2D',\n",
       "  'inputs': array([1], dtype=int32),\n",
       "  'outputs': array([497], dtype=int32)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter2._get_ops_details()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc4fa390-b866-4643-80ee-fe23f4e1b1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Placeholder',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'shape_signature': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Relu',\n",
       "  'index': 1,\n",
       "  'shape': array([  1, 112, 112,  64], dtype=int32),\n",
       "  'shape_signature': array([  1, 112, 112,  64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter2.get_tensor_details()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4578c9e-4a8d-45c0-80e5-f0e33a6499fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder \t [  1 224 224   3]\n",
      "conv2d/kernel \t [64  7  7  3]\n",
      "conv2d/Conv2D_bias \t [64]\n",
      "----\n",
      "block-0/denseblock-0-0/Relu \t [ 1 56 56 64]\n",
      "block-0/denseblock-0-0/conv2d/kernel \t [32  3  3 64]\n",
      "block-0/denseblock-0-0/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/denseblock-0-1/Relu \t [ 1 56 56 96]\n",
      "block-0/denseblock-0-1/conv2d/kernel \t [32  3  3 96]\n",
      "block-0/denseblock-0-1/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/denseblock-0-2/Relu \t [  1  56  56 128]\n",
      "block-0/denseblock-0-2/conv2d/kernel \t [ 32   3   3 128]\n",
      "block-0/denseblock-0-2/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/denseblock-0-3/Relu \t [  1  56  56 160]\n",
      "block-0/denseblock-0-3/conv2d/kernel \t [ 32   3   3 160]\n",
      "block-0/denseblock-0-3/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/denseblock-0-4/Relu \t [  1  56  56 192]\n",
      "block-0/denseblock-0-4/conv2d/kernel \t [ 32   3   3 192]\n",
      "block-0/denseblock-0-4/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/denseblock-0-5/Relu \t [  1  56  56 224]\n",
      "block-0/denseblock-0-5/conv2d/kernel \t [ 32   3   3 224]\n",
      "block-0/denseblock-0-5/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-0/Relu \t [  1  56  56 256]\n",
      "block-0/conv2d/kernel \t [128   1   1 256]\n",
      "block-0/conv2d/Conv2D_bias \t [128]\n",
      "----\n",
      "block-1/denseblock-1-0/Relu \t [  1  28  28 128]\n",
      "block-1/denseblock-1-0/conv2d/kernel \t [ 32   3   3 128]\n",
      "block-1/denseblock-1-0/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-1/Relu \t [  1  28  28 160]\n",
      "block-1/denseblock-1-1/conv2d/kernel \t [ 32   3   3 160]\n",
      "block-1/denseblock-1-1/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-2/Relu \t [  1  28  28 192]\n",
      "block-1/denseblock-1-2/conv2d/kernel \t [ 32   3   3 192]\n",
      "block-1/denseblock-1-2/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-3/Relu \t [  1  28  28 224]\n",
      "block-1/denseblock-1-3/conv2d/kernel \t [ 32   3   3 224]\n",
      "block-1/denseblock-1-3/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-4/Relu \t [  1  28  28 256]\n",
      "block-1/denseblock-1-4/conv2d/kernel \t [ 32   3   3 256]\n",
      "block-1/denseblock-1-4/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-5/Relu \t [  1  28  28 288]\n",
      "block-1/denseblock-1-5/conv2d/kernel \t [ 32   3   3 288]\n",
      "block-1/denseblock-1-5/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-6/Relu \t [  1  28  28 320]\n",
      "block-1/denseblock-1-6/conv2d/kernel \t [ 32   3   3 320]\n",
      "block-1/denseblock-1-6/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-7/Relu \t [  1  28  28 352]\n",
      "block-1/denseblock-1-7/conv2d/kernel \t [ 32   3   3 352]\n",
      "block-1/denseblock-1-7/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-8/Relu \t [  1  28  28 384]\n",
      "block-1/denseblock-1-8/conv2d/kernel \t [ 32   3   3 384]\n",
      "block-1/denseblock-1-8/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-9/Relu \t [  1  28  28 416]\n",
      "block-1/denseblock-1-9/conv2d/kernel \t [ 32   3   3 416]\n",
      "block-1/denseblock-1-9/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-10/Relu \t [  1  28  28 448]\n",
      "block-1/denseblock-1-10/conv2d/kernel \t [ 32   3   3 448]\n",
      "block-1/denseblock-1-10/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/denseblock-1-11/Relu \t [  1  28  28 480]\n",
      "block-1/denseblock-1-11/conv2d/kernel \t [ 32   3   3 480]\n",
      "block-1/denseblock-1-11/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-1/Relu \t [  1  28  28 512]\n",
      "block-1/conv2d/kernel \t [256   1   1 512]\n",
      "block-1/conv2d/Conv2D_bias \t [256]\n",
      "----\n",
      "block-2/denseblock-2-0/Relu \t [  1  14  14 256]\n",
      "block-2/denseblock-2-0/conv2d/kernel \t [ 32   3   3 256]\n",
      "block-2/denseblock-2-0/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-1/Relu \t [  1  14  14 288]\n",
      "block-2/denseblock-2-1/conv2d/kernel \t [ 32   3   3 288]\n",
      "block-2/denseblock-2-1/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-2/Relu \t [  1  14  14 320]\n",
      "block-2/denseblock-2-2/conv2d/kernel \t [ 32   3   3 320]\n",
      "block-2/denseblock-2-2/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-3/Relu \t [  1  14  14 352]\n",
      "block-2/denseblock-2-3/conv2d/kernel \t [ 32   3   3 352]\n",
      "block-2/denseblock-2-3/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-4/Relu \t [  1  14  14 384]\n",
      "block-2/denseblock-2-4/conv2d/kernel \t [ 32   3   3 384]\n",
      "block-2/denseblock-2-4/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-5/Relu \t [  1  14  14 416]\n",
      "block-2/denseblock-2-5/conv2d/kernel \t [ 32   3   3 416]\n",
      "block-2/denseblock-2-5/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-6/Relu \t [  1  14  14 448]\n",
      "block-2/denseblock-2-6/conv2d/kernel \t [ 32   3   3 448]\n",
      "block-2/denseblock-2-6/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-7/Relu \t [  1  14  14 480]\n",
      "block-2/denseblock-2-7/conv2d/kernel \t [ 32   3   3 480]\n",
      "block-2/denseblock-2-7/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-8/Relu \t [  1  14  14 512]\n",
      "block-2/denseblock-2-8/conv2d/kernel \t [ 32   3   3 512]\n",
      "block-2/denseblock-2-8/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-9/Relu \t [  1  14  14 544]\n",
      "block-2/denseblock-2-9/conv2d/kernel \t [ 32   3   3 544]\n",
      "block-2/denseblock-2-9/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-10/Relu \t [  1  14  14 576]\n",
      "block-2/denseblock-2-10/conv2d/kernel \t [ 32   3   3 576]\n",
      "block-2/denseblock-2-10/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-11/Relu \t [  1  14  14 608]\n",
      "block-2/denseblock-2-11/conv2d/kernel \t [ 32   3   3 608]\n",
      "block-2/denseblock-2-11/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-12/Relu \t [  1  14  14 640]\n",
      "block-2/denseblock-2-12/conv2d/kernel \t [ 32   3   3 640]\n",
      "block-2/denseblock-2-12/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-13/Relu \t [  1  14  14 672]\n",
      "block-2/denseblock-2-13/conv2d/kernel \t [ 32   3   3 672]\n",
      "block-2/denseblock-2-13/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-14/Relu \t [  1  14  14 704]\n",
      "block-2/denseblock-2-14/conv2d/kernel \t [ 32   3   3 704]\n",
      "block-2/denseblock-2-14/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-15/Relu \t [  1  14  14 736]\n",
      "block-2/denseblock-2-15/conv2d/kernel \t [ 32   3   3 736]\n",
      "block-2/denseblock-2-15/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-16/Relu \t [  1  14  14 768]\n",
      "block-2/denseblock-2-16/conv2d/kernel \t [ 32   3   3 768]\n",
      "block-2/denseblock-2-16/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-17/Relu \t [  1  14  14 800]\n",
      "block-2/denseblock-2-17/conv2d/kernel \t [ 32   3   3 800]\n",
      "block-2/denseblock-2-17/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-18/Relu \t [  1  14  14 832]\n",
      "block-2/denseblock-2-18/conv2d/kernel \t [ 32   3   3 832]\n",
      "block-2/denseblock-2-18/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-19/Relu \t [  1  14  14 864]\n",
      "block-2/denseblock-2-19/conv2d/kernel \t [ 32   3   3 864]\n",
      "block-2/denseblock-2-19/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-20/Relu \t [  1  14  14 896]\n",
      "block-2/denseblock-2-20/conv2d/kernel \t [ 32   3   3 896]\n",
      "block-2/denseblock-2-20/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-21/Relu \t [  1  14  14 928]\n",
      "block-2/denseblock-2-21/conv2d/kernel \t [ 32   3   3 928]\n",
      "block-2/denseblock-2-21/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-22/Relu \t [  1  14  14 960]\n",
      "block-2/denseblock-2-22/conv2d/kernel \t [ 32   3   3 960]\n",
      "block-2/denseblock-2-22/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/denseblock-2-23/Relu \t [  1  14  14 992]\n",
      "block-2/denseblock-2-23/conv2d/kernel \t [ 32   3   3 992]\n",
      "block-2/denseblock-2-23/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-2/Relu \t [   1   14   14 1024]\n",
      "block-2/conv2d/kernel \t [ 512    1    1 1024]\n",
      "block-2/conv2d/Conv2D_bias \t [512]\n",
      "----\n",
      "block-3/denseblock-3-0/Relu \t [  1   7   7 512]\n",
      "block-3/denseblock-3-0/conv2d/kernel \t [ 32   3   3 512]\n",
      "block-3/denseblock-3-0/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-1/Relu \t [  1   7   7 544]\n",
      "block-3/denseblock-3-1/conv2d/kernel \t [ 32   3   3 544]\n",
      "block-3/denseblock-3-1/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-2/Relu \t [  1   7   7 576]\n",
      "block-3/denseblock-3-2/conv2d/kernel \t [ 32   3   3 576]\n",
      "block-3/denseblock-3-2/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-3/Relu \t [  1   7   7 608]\n",
      "block-3/denseblock-3-3/conv2d/kernel \t [ 32   3   3 608]\n",
      "block-3/denseblock-3-3/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-4/Relu \t [  1   7   7 640]\n",
      "block-3/denseblock-3-4/conv2d/kernel \t [ 32   3   3 640]\n",
      "block-3/denseblock-3-4/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-5/Relu \t [  1   7   7 672]\n",
      "block-3/denseblock-3-5/conv2d/kernel \t [ 32   3   3 672]\n",
      "block-3/denseblock-3-5/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-6/Relu \t [  1   7   7 704]\n",
      "block-3/denseblock-3-6/conv2d/kernel \t [ 32   3   3 704]\n",
      "block-3/denseblock-3-6/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-7/Relu \t [  1   7   7 736]\n",
      "block-3/denseblock-3-7/conv2d/kernel \t [ 32   3   3 736]\n",
      "block-3/denseblock-3-7/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-8/Relu \t [  1   7   7 768]\n",
      "block-3/denseblock-3-8/conv2d/kernel \t [ 32   3   3 768]\n",
      "block-3/denseblock-3-8/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-9/Relu \t [  1   7   7 800]\n",
      "block-3/denseblock-3-9/conv2d/kernel \t [ 32   3   3 800]\n",
      "block-3/denseblock-3-9/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-10/Relu \t [  1   7   7 832]\n",
      "block-3/denseblock-3-10/conv2d/kernel \t [ 32   3   3 832]\n",
      "block-3/denseblock-3-10/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-11/Relu \t [  1   7   7 864]\n",
      "block-3/denseblock-3-11/conv2d/kernel \t [ 32   3   3 864]\n",
      "block-3/denseblock-3-11/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-12/Relu \t [  1   7   7 896]\n",
      "block-3/denseblock-3-12/conv2d/kernel \t [ 32   3   3 896]\n",
      "block-3/denseblock-3-12/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-13/Relu \t [  1   7   7 928]\n",
      "block-3/denseblock-3-13/conv2d/kernel \t [ 32   3   3 928]\n",
      "block-3/denseblock-3-13/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-14/Relu \t [  1   7   7 960]\n",
      "block-3/denseblock-3-14/conv2d/kernel \t [ 32   3   3 960]\n",
      "block-3/denseblock-3-14/conv2d/Conv2D_bias \t [32]\n",
      "----\n",
      "block-3/denseblock-3-15/Relu \t [  1   7   7 992]\n",
      "block-3/denseblock-3-15/conv2d/kernel \t [ 32   3   3 992]\n",
      "block-3/denseblock-3-15/conv2d/Conv2D_bias \t [32]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "ops = interpreter2._get_ops_details()\n",
    "cnt = 0\n",
    "for op_index, op in enumerate(ops):\n",
    "    if op['op_name'] == \"CONV_2D\":\n",
    "        cnt += 1\n",
    "        for tensor_idx in op['inputs']:\n",
    "            tensor = interpreter2._get_tensor_details(tensor_idx)\n",
    "            tensor_shape = tensor['shape']\n",
    "            #print(tensor_shape)\n",
    "            print(tensor['name'], \"\\t\", tensor['shape'])\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e52781d-d4f9-4bd9-8a1a-a6fe0cfa64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder \t [  1 224 224   3]\n",
      "{'name': 'Placeholder', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([  1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "conv2d/kernel \t [64  7  7  3]\n",
      "{'name': 'conv2d/kernel', 'index': 491, 'shape': array([64,  7,  7,  3], dtype=int32), 'shape_signature': array([64,  7,  7,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "conv2d/Conv2D_bias \t [64]\n",
      "{'name': 'conv2d/Conv2D_bias', 'index': 490, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "----\n",
      "block-0/denseblock-0-0/Relu \t [ 1 56 56 64]\n",
      "{'name': 'block-0/denseblock-0-0/Relu', 'index': 10, 'shape': array([ 1, 56, 56, 64], dtype=int32), 'shape_signature': array([ 1, 56, 56, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "block-0/denseblock-0-0/conv2d/kernel \t [32  3  3 64]\n",
      "{'name': 'block-0/denseblock-0-0/conv2d/kernel', 'index': 17, 'shape': array([32,  3,  3, 64], dtype=int32), 'shape_signature': array([32,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "block-0/denseblock-0-0/conv2d/Conv2D_bias \t [32]\n",
      "{'name': 'block-0/denseblock-0-0/conv2d/Conv2D_bias', 'index': 16, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "----\n",
      "block-0/denseblock-0-1/Relu \t [ 1 56 56 96]\n",
      "{'name': 'block-0/denseblock-0-1/Relu', 'index': 18, 'shape': array([ 1, 56, 56, 96], dtype=int32), 'shape_signature': array([ 1, 56, 56, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "block-0/denseblock-0-1/conv2d/kernel \t [32  3  3 96]\n",
      "{'name': 'block-0/denseblock-0-1/conv2d/kernel', 'index': 25, 'shape': array([32,  3,  3, 96], dtype=int32), 'shape_signature': array([32,  3,  3, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "block-0/denseblock-0-1/conv2d/Conv2D_bias \t [32]\n",
      "{'name': 'block-0/denseblock-0-1/conv2d/Conv2D_bias', 'index': 24, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "ops = interpreter2._get_ops_details()\n",
    "cnt = 0\n",
    "for op_index, op in enumerate(ops):\n",
    "    if op['op_name'] == \"CONV_2D\":\n",
    "        cnt += 1\n",
    "        for tensor_idx in op['inputs']:\n",
    "            tensor = interpreter2._get_tensor_details(tensor_idx)\n",
    "            tensor_shape = tensor['shape']\n",
    "            #print(tensor_shape)\n",
    "            print(tensor['name'], \"\\t\", tensor['shape'])\n",
    "            print(tensor)\n",
    "        print(\"----\")\n",
    "    if op_index == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "956343d6-aa0b-4c2b-bcc5-a70c21a18b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.lite' has no attribute 'ModelAnalyzer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-607c2f9bdeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.lite' has no attribute 'ModelAnalyzer'"
     ]
    }
   ],
   "source": [
    "analyzer = tf.lite.ModelAnalyzer(interpreter2, \"txt\")\n",
    "analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e16f19f4-666c-4ac6-83f9-81375bc81421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.lite.python.interpreter_wrapper._pywrap_tensorflow_interpreter_wrapper.InterpreterWrapper"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(interpreter._interpreter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04802e-f1d3-4b0f-a6d5-40efa44af282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
